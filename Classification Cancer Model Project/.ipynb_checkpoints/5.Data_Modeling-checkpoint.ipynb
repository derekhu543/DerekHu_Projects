{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GnbbsQu2SyFi"
   },
   "outputs": [],
   "source": [
    "###Data Modeling###\n",
    "#Import what I need for modeling\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier, RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-IB9SaAuUm0s"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./Data_Files/final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3iUn5acK4yCs",
    "outputId": "36c07052-36c1-4340-d335-f21aa5ea6f0e"
   },
   "outputs": [],
   "source": [
    "#My list of all columns with dummy variables\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IbESdH2vTAFe"
   },
   "outputs": [],
   "source": [
    "#I want to standardize the data so make the mean 0 and the standard deviation 1\n",
    "\n",
    "ss = StandardScaler()\n",
    "scaled = ss.fit_transform(data)\n",
    "\n",
    "corr_data = pd.DataFrame(scaled, columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nas996JhYAKT"
   },
   "outputs": [],
   "source": [
    "#I decided to not use PCA or visualizations and use Tableau instead\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#plt.figure(figsize=(20,15))\n",
    "#heatmap = sns.heatmap(corr_data.corr(), vmin=0, annot=True, fmt='.2f', cmap='YlGnBu')\n",
    "\n",
    "#plt.title('Correlations on Scaled Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vw4hXKjCmKtp",
    "outputId": "350ed378-391a-4156-ac7d-fc26bbf89dff"
   },
   "outputs": [],
   "source": [
    "#This of course is inaccurate but I wanted to see if my variables generally made sense.\n",
    "#Based on my research, it makes sense. High cholestral, smoking, and worse health increases cancer rates\n",
    "#Managerial jobs cause cancer because of lack of exercise and increased health problems\n",
    "data.corr()['cancer_count'].sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KPRKWAXkKJeX"
   },
   "outputs": [],
   "source": [
    "#PCA - This is how I would have used PCA\n",
    "#import seaborn as sns\n",
    "#g = sns.PairGrid(data)\n",
    "#g = g.map_lower(sns.regplot)    # Regression plots in lower triangle.\n",
    "#g = g.map_upper(sns.kdeplot, cmap=\"Blues\", shade=True, shade_lowest=False)  # KDE plots in upper triangle.\n",
    "#g = g.map_diag(plt.hist)        # Histograms along diagonal.\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcVYmcYvbxmK"
   },
   "outputs": [],
   "source": [
    "#I reran models multiple times, dropped unimportant variables using Tableau as feature selection\n",
    "#Selected variables that had the best accuracy and highest metrics. Kept about 20 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDuKeZj-YI05"
   },
   "outputs": [],
   "source": [
    "#feature selection - train/test data \n",
    "X = data.drop(columns=['cancer_count'])\n",
    "y = data['cancer_count']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-TcatbudsYDl",
    "outputId": "d8ee94c0-0de0-4194-8742-48cc932106e2"
   },
   "outputs": [],
   "source": [
    "#Baseline using dummy regressor - sensitivity/recall\n",
    "dummy_regr = DummyClassifier()\n",
    "dummy_regr.fit(X_train, y_train)\n",
    "\n",
    "dummy_regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_onVHPrLcxp",
    "outputId": "fc9041b0-8784-46d6-d1a7-be382d029e2c"
   },
   "outputs": [],
   "source": [
    "#Baseline will be 0.5 using balanced accuracy score - \n",
    "#I avoided using regular accuracy score since my data is so imbalanced \n",
    "y_pred = dummy_regr.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_hzhKSWaEDgs"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5mX97UKFMws"
   },
   "outputs": [],
   "source": [
    "#SMOTE - only use dummy variables processing categorical data (X-values)\n",
    "#Only use smote on training test not testing data to prevent data leakage\n",
    "#Testing data represents real life so I won't use smote\n",
    "#Make training data 50/50 to balance it out\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "ada = ADASYN(random_state=100)\n",
    "X_train, y_train = ada.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9B0SUCMfChT",
    "outputId": "6557ae29-0d6b-48ca-8644-5fa274d1a93c"
   },
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2lXOo0JQoc38",
    "outputId": "8cd01d11-280d-402c-a835-f1e09728f953"
   },
   "outputs": [],
   "source": [
    "#train data now 50/50\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uOmG3T66o5JZ",
    "outputId": "383eca9c-946c-4e56-9687-3334453c0352"
   },
   "outputs": [],
   "source": [
    "#testing data still the same, very imbalanced\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yr7Fl7Lzlf9p"
   },
   "outputs": [],
   "source": [
    "#Used pipeline to fit standardscaler and various model types\n",
    "#I tried using polynomial features but it keeps crashing from overload\n",
    "pipe_ada = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('abc', AdaBoostClassifier(learning_rate=0.5, n_estimators=50, random_state=1))\n",
    "])\n",
    "\n",
    "pipe_grad = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('gbc', GradientBoostingClassifier(random_state=1))\n",
    "])\n",
    "\n",
    "pipe_km = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('km', KMeans(random_state=1))\n",
    "])\n",
    "\n",
    "pipe_dbs = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('dbs', DBSCAN())\n",
    "])\n",
    "\n",
    "pipe_xgb = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('xgb', xgb.XGBClassifier(n_estimators = 200))\n",
    "])\n",
    "\n",
    "pipe_log = Pipeline([\n",
    "#    (\"vectorizer\", CountVectorizer())\n",
    "    ('ss', StandardScaler()),\n",
    "    ('log', LogisticRegression())\n",
    "])\n",
    "\n",
    "#n_estimators=70, random_state=42, max_features=none, min_samples_leaf=10\n",
    "pipe_forest = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('forest', RandomForestClassifier(n_estimators=70, random_state=42, min_samples_leaf=10))\n",
    "])\n",
    "\n",
    "pipe_svc = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('svc', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipe_dectree = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('dec', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "pipe_svm = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('dec', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = Pipeline([  # giving the pipeline a list of things to do!\n",
    "    ('pf', PolynomialFeatures(include_bias=False)),  # inside the tuple: a name for the step, and the class we want to use\n",
    "    ('ss', StandardScaler()),\n",
    "    ('dec', DecisionTreeClassifier())              # last step: estimator\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(zip(pipe['pf'].get_feature_names_out(), pipe['dec'].coef_)).sort_values(by=1, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o_RSflRnd5tk",
    "outputId": "a45cda08-bb56-404b-d7b7-321b12d28bb4"
   },
   "outputs": [],
   "source": [
    "#Logarithmic regression has the highest accuracy\n",
    "\n",
    "pipe_log.fit(X_train, y_train)\n",
    "\n",
    "pipe_log.score(X_train, y_train), pipe_log.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "snRaBtwO4P8s",
    "outputId": "8c0b4893-ad92-4f3f-9964-3cee8bc6ca53"
   },
   "outputs": [],
   "source": [
    "#Used balanced accuracy score to compensate for imbalanced y-value\n",
    "y_pred = pipe_log.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_acXZd0Tl4GK",
    "outputId": "82ad95d5-7b94-4bb7-8579-b2ed3aa9bbed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9605483630380035, 0.9267498227663773)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_ada.fit(X_train, y_train)\n",
    "\n",
    "pipe_ada.score(X_train, y_train), pipe_ada.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QR92R3YF4ZiB",
    "outputId": "38ccb8c8-0162-4c16-f300-8009e8a1467f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7279498520428997"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pipe_ada.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0MrYLlj7RN2",
    "outputId": "2d200613-f80c-41b7-b47f-a7c97e037524"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9773878842404156, 0.9571573642965262)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_grad.fit(X_train, y_train)\n",
    "\n",
    "pipe_grad.score(X_train, y_train), pipe_grad.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sDe2JrYA4cZL",
    "outputId": "e9c07745-c99a-4edf-e19d-4ccdd4aee705"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5388275856277444"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pipe_grad.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yMJtcgxJ7np8",
    "outputId": "93702e9d-e280-47ee-fe43-6ff8e89a0d7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9816588015344533, 0.959418290509858)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_xgb.fit(X_train, y_train)\n",
    "\n",
    "pipe_xgb.score(X_train, y_train), pipe_xgb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zp9UN4OH5Tck",
    "outputId": "394e3075-89f3-40c9-fbaa-200f585fb0df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5126622988093101"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pipe_xgb.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nSEWCSLlr_lV",
    "outputId": "d22375b1-44a9-454b-951c-aa7a6c7a8e4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-13787654.725806171, -2537975.8882192723)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_km.fit(X_train, y_train)\n",
    "\n",
    "pipe_km.score(X_train, y_train), pipe_km.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RaX7eTjm7lYH",
    "outputId": "08e55517-1a54-4f1c-d0cf-67ccd20dd8fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.933168553965243)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_dectree.fit(X_train, y_train)\n",
    "\n",
    "pipe_dectree.score(X_train, y_train), pipe_dectree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74fZ2WXs7-pR",
    "outputId": "632a12ba-d8f6-4c08-a891-3f2a475c8341"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5950478721785016"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pipe_dectree.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W_k_WMtw8CsR",
    "outputId": "cc9d0ae1-d650-453c-b10b-8f5de4f39209"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999799330432543, 0.9566400337222892)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_svc.fit(X_train, y_train)\n",
    "\n",
    "pipe_svc.score(X_train, y_train), pipe_svc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BYECcmjXRICx",
    "outputId": "87953b71-fd4a-4003-850c-390529a199a3"
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12928\\1038861374.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe_svc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mbalanced_accuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    970\u001b[0m             \u001b[0mTransformed\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m         \"\"\"\n\u001b[1;32m--> 972\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    973\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1344\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1345\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "y_pred = pipe_svc.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vipG4eohRK1e",
    "outputId": "1e47153d-32e7-4450-c3f5-f6b28fb771ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9795317041194118, 0.9605104328332471)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_forest.fit(X_train, y_train)\n",
    "\n",
    "pipe_forest.score(X_train, y_train), pipe_forest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r6rTh3SBRRPM",
    "outputId": "00713848-e1e0-4380-dd51-0c74e5ccbf40"
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12928\\1616075208.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe_forest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mbalanced_accuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    970\u001b[0m             \u001b[0mTransformed\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m         \"\"\"\n\u001b[1;32m--> 972\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    973\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1344\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1345\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "y_pred = pipe_forest.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qciw2JmbK6bR",
    "outputId": "6ea40e23-5c37-47c5-a161-8bd9f8ceb59a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "         No       0.99      0.99      0.81      0.99      0.90      0.82    200558\n",
      "        Yes       0.78      0.81      0.99      0.79      0.90      0.79      8206\n",
      "\n",
      "avg / total       0.98      0.98      0.82      0.98      0.90      0.81    208764\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##I used metrics such as F1 score, preceision, and recall\n",
    "#For cancer, true positives and true negatives are good because accuracy is important\n",
    "\n",
    "#False positives - false alarms, when people test positive for cancer when they don't have cancer\n",
    "#False positives result in costly medical procedures or an extra scan which are unnecessary\n",
    "\n",
    "#False negative - very deadly, person test negative for cancer when they don't have cancer\n",
    "#Avoid at all costs - could result in lives lost\n",
    "\n",
    "#accuracy - important measure to see how correct your model is\n",
    "#precision - if you want to be more confident of your true positives\n",
    "#recall - useful if false positives are far better than false negatives (I chose method, would rather get false alarms than lives lost)\n",
    "#specificity - useful if you don't want any false alarms\n",
    "\n",
    "#decision tree is second favorite model. High recall scores and high accuracy\n",
    "y_test = data['cancer_count']  \n",
    "predict_grad = pipe_dectree.predict(data.drop(columns = ['cancer_count']))\n",
    "print(classification_report_imbalanced(y_test, predict_grad, target_names=['No', 'Yes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "omR6Y-VOVQqK",
    "outputId": "768c4657-024a-48c4-dc59-2c3a65eaffdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "         No       1.00      0.83      0.90      0.91      0.87      0.75    200558\n",
      "        Yes       0.18      0.90      0.83      0.30      0.87      0.76      8206\n",
      "\n",
      "avg / total       0.96      0.84      0.90      0.88      0.87      0.75    208764\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logarithmic regression is my preferred model. I want false positives to be as low as possible\n",
    "y_test = data['cancer_count']  \n",
    "predict_grad = pipe_log.predict(data.drop(columns = ['cancer_count']))\n",
    "print(classification_report_imbalanced(y_test, predict_grad, target_names=['No', 'Yes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LhQFOCibVeVR",
    "outputId": "8371c02c-f878-497e-bf8d-33ebb0826744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "         No       0.98      0.94      0.51      0.96      0.69      0.50    200558\n",
      "        Yes       0.27      0.51      0.94      0.35      0.69      0.46      8206\n",
      "\n",
      "avg / total       0.95      0.93      0.52      0.94      0.69      0.50    208764\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = data['cancer_count']  \n",
    "predict_grad = pipe_ada.predict(data.drop(columns = ['cancer_count']))\n",
    "print(classification_report_imbalanced(y_test, predict_grad, target_names=['No', 'Yes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qZB5mngHVVnS",
    "outputId": "77379789-47d4-4c9b-fe52-97968590a56e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "         No       0.96      0.99      0.08      0.98      0.28      0.09    200558\n",
      "        Yes       0.33      0.08      0.99      0.13      0.28      0.07      8206\n",
      "\n",
      "avg / total       0.94      0.96      0.12      0.94      0.28      0.09    208764\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = data['cancer_count']  \n",
    "predict_grad = pipe_grad.predict(data.drop(columns = ['cancer_count']))\n",
    "print(classification_report_imbalanced(y_test, predict_grad, target_names=['No', 'Yes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jf3HUvoUXXaD",
    "outputId": "93b7f8db-2eba-44a4-e316-28768b048c7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "         No       0.96      1.00      0.10      0.98      0.31      0.10    200558\n",
      "        Yes       0.82      0.10      1.00      0.17      0.31      0.09      8206\n",
      "\n",
      "avg / total       0.96      0.96      0.13      0.95      0.31      0.10    208764\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = data['cancer_count']  \n",
    "predict_grad = pipe_xgb.predict(data.drop(columns = ['cancer_count']))\n",
    "print(classification_report_imbalanced(y_test, predict_grad, target_names=['No', 'Yes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "cfVd1qPLRBUo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "         No       0.96      1.00      0.01      0.98      0.11      0.01    200558\n",
      "        Yes       0.63      0.01      1.00      0.03      0.11      0.01      8206\n",
      "\n",
      "avg / total       0.95      0.96      0.05      0.94      0.11      0.01    208764\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_test = data['cancer_count']  \n",
    "predict_grad = pipe_forest.predict(data.drop(columns = ['cancer_count']))\n",
    "print(classification_report_imbalanced(y_test, predict_grad, target_names=['No', 'Yes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52186</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52187</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52188</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52189</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52190</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52191 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "...   ..\n",
       "52186  0\n",
       "52187  0\n",
       "52188  0\n",
       "52189  0\n",
       "52190  0\n",
       "\n",
       "[52191 rows x 1 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict for decision trees\n",
    "y_pred = pipe_forest.predict(X_test)\n",
    "df = pd.DataFrame(y_pred)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R squared for decision trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "L7oruQehmeBT"
   },
   "outputs": [],
   "source": [
    "#I wanted to use polynomialfeatures but comptuer kept crashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ywzIUz_LpXG5"
   },
   "outputs": [],
   "source": [
    "##Neural Network \n",
    "import pandas as pd\n",
    "data = pd.read_csv('./Data_Files/final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PL7i4b1j9DuE"
   },
   "outputs": [],
   "source": [
    "#train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = data.drop(columns=['cancer_count'])\n",
    "y = data['cancer_count']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lleHS1_h9NV5"
   },
   "outputs": [],
   "source": [
    "#standardize data\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZADjy6LbGkY_"
   },
   "outputs": [],
   "source": [
    "#SMOTE - only use dummy variables processing categorical data (X-values)\n",
    "#Only use smote on training test not training data, prevent data leakage, test represent real life\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "ada = ADASYN(random_state=100)\n",
    "X_train_ada, y_train_ada = ada.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W9ATbBNOGhRX",
    "outputId": "f2bf589b-c924-4149-cd75-7fa5a01bdb12"
   },
   "outputs": [],
   "source": [
    "#Use neural networks, balance classes using smote or oversample from cancer class\n",
    "#Look at metrics - add more\n",
    "#When look at onehotencoded variables - correlation is not accurate (are important but could be random luck)\n",
    "#Visualizations - delete variables before onehotencoding\n",
    "#Boxplot to visualize features\n",
    "\n",
    "#balanced accuracy, I did NOT balance my data as I ran out of time.\n",
    "#WOULD NOT RECOMMEND as low accuracy\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "#kernel regularizer did not work, dropout does not work, binaryaccuracy, dropout not work\n",
    "# hidden w/ 60 nodes, two layers\n",
    "\n",
    "#loss kept increasing for val_accuracy\n",
    "model.add(Input(shape = X_train.shape[1]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#use metrics - precision, recall\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['Accuracy'])\n",
    "history = model.fit(\n",
    "    X_train_ada, y_train_ada,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=15,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "G1D3rf069I3O",
    "outputId": "2e11aa43-ddef-45fc-e243-0f8b2fc1b506"
   },
   "outputs": [],
   "source": [
    "#Struggled with accuracy, high losses for testing\n",
    "#Tries multiple methods but ran out of time\n",
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(train_loss, label='Training Loss', color='navy')\n",
    "plt.plot(test_loss, label='Testing Loss', color='skyblue')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6NwE_Me5EaPW",
    "outputId": "9a76039b-ea92-4c68-8b74-ab1c65569cf9"
   },
   "outputs": [],
   "source": [
    "#Binary accuracy only slightly helped\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "#kernel regularizer did not work, dropout does not work, binaryaccuracy, dropout not work\n",
    "# hidden w/ 60 nodes, two layers\n",
    "\n",
    "#loss kept increasing for val_accuracy\n",
    "model.add(Input(shape = X_train.shape[1]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#use metrics - precision, recall\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['BinaryAccuracy'])\n",
    "history = model.fit(\n",
    "    X_train_ada, y_train_ada,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=15,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8oJEWeuExJE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
